{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QIQC_model_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1544112859269,"user_tz":-120,"elapsed":38902,"user":{"displayName":"Quentin Legrand","photoUrl":"https://lh6.googleusercontent.com/-IXHiOGs04sE/AAAAAAAAAAI/AAAAAAAAAFk/ppsEvqzCcGw/s64/photo.jpg","userId":"00421493000358847389"}},"id":"ODRJ7bX8vV9M","outputId":"1e6d2187-38bb-4d63-a67b-8a744610f9b1","colab":{"base_uri":"https://localhost:8080/","height":129}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"CYb4xYXtV75L","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","from datetime import datetime as dt\n","import time\n","import re\n","\n","DRIVE_PATH = \"/content/gdrive/My Drive/Colab Notebooks/\"\n","TRAIN_FILE = \"datasets/train.csv\"\n","CORRECTED_TRAIN_FILE = \"datasets/corrected_train.csv\"\n","TEST_FILE = \"datasets/test.csv\"\n","GLOVE_FILE = \"embeddings/glove.840B.300d/glove.840B.300d.txt\""],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1544112861827,"user_tz":-120,"elapsed":41427,"user":{"displayName":"Quentin Legrand","photoUrl":"https://lh6.googleusercontent.com/-IXHiOGs04sE/AAAAAAAAAAI/AAAAAAAAAFk/ppsEvqzCcGw/s64/photo.jpg","userId":"00421493000358847389"}},"id":"_HRVliA5WoLj","outputId":"c3748839-1ecf-4efa-9c0c-1925a141fcd9","colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"8PHq3bJ-V75f"},"cell_type":"markdown","source":["# Toolbox"]},{"metadata":{"colab_type":"code","id":"xIBMtV8dV75k","colab":{}},"cell_type":"code","source":["def reset_graph(seed=42):\n","    tf.reset_default_graph()\n","    tf.set_random_seed(seed)\n","    np.random.seed(seed)\n","\n","def load_data(path = DRIVE_PATH, file = CORRECTED_TRAIN_FILE):\n","    csv_path = os.path.join(path,file)\n","    return pd.read_csv(csv_path)\n","\n","def tokenize(sentences_list):\n","    return [re.findall(r\"[\\w]+|[']|[.,!?;]\", str(x)) for x in sentences_list] \n","    \n","def get_vocab(sentences):\n","    vocab={}\n","    for sentence in sentences:\n","        for word in sentence:\n","            try:\n","                vocab[word] +=1\n","            except KeyError:\n","                vocab[word] = 1\n","    return vocab\n","\n","def glove_embeddings(vocabulary_in_set, drive = DRIVE_PATH, gloveFile = GLOVE_FILE ,extract = -1):\n","\n","    glove_file = os.path.join(drive,gloveFile)\n","  \n","    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","\n","    embeddings = []\n","    words_id = {}\n","    f = open(glove_file,'r', encoding=\"utf8\")\n","    increment = 0\n","    words_id[\"\"]=0\n","    first = True\n","    i = 1\n","    \n","    for line in f:\n","        word, vect = get_coefs(*line.split(\" \"))\n","        if first:\n","            embeddings.append(np.zeros_like(vect))\n","            first = False\n","        if word in vocabulary_in_set:\n","            embeddings.append(vect)\n","            words_id[word] = i\n","            i += 1\n","            if increment == extract - 1:\n","                break\n","            elif extract != -1:\n","                increment += 1\n","    f.close()   \n","    return np.array(embeddings), words_id\n","\n","def df_to_data_target(df, data_col = \"corrected_question_text\", target_col = \"target\"):\n","    data = df[data_col]\n","    target = df[target_col]\n","    return np.c_[data, target]\n","\n","def embed_and_pad(X, embeddings, n_dims, width):\n","    padded_X = np.zeros((len(X),width,n_dims))\n","    i = 0\n","    for sentence in X:\n","        j = 0\n","        for word in sentence:\n","            padded_X[i,j,:] = embeddings[word]\n","            j += 1\n","        i +=1\n","    return padded_X"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"xPTqJyieV75u","colab":{}},"cell_type":"code","source":["class data_split_and_batch:\n","    def __init__(self, data_targets, dv=0, cv=0, batch_size=500, words_ids = None, seed=42):\n","        self.seed = seed\n","        np.random.seed(seed)\n","        self.batch_length = batch_size\n","        self.pointer = 0\n","        self.reshuffle_seed = 0\n","        self.__split__(data_targets=data_targets, dv=dv, cv=cv, words_ids=words_ids)\n","    \n","    def __split__(self, data_targets, dv, cv, words_ids):\n","        positive_data_targets = data_targets[data_targets[:,1]==1]\n","        negative_data_targets = data_targets[data_targets[:,1]==0]\n","        \n","        positive_length = len(positive_data_targets)\n","        negative_length = len(negative_data_targets)\n","  \n","        pos_data_targets = positive_data_targets[np.random.permutation(positive_length), :]\n","        neg_data_targets = negative_data_targets[np.random.permutation(negative_length), :]\n","        \n","        if dv != 0:\n","            dv_positive = int(dv * positive_length/(positive_length + negative_length))\n","            dv_negative = dv - dv_positive\n","            dv_data_targets = np.concatenate((positive_data_targets[0:dv_positive,:], negative_data_targets[0:dv_negative,:]))\n","            dv_data_targets = dv_data_targets[np.random.permutation(dv), :]\n","            self.dv_targets = dv_data_targets[:,1].astype(float)\n","            X_dev = self.__tokenize__(dv_data_targets[:,0])\n","            self.X_dv_lengths = np.array(list(map(len, X_dev)))\n","            if words_ids == None:\n","                self.dv_data = X_dev\n","            else:\n","                self.dv_data = self.__ids_and_pad__(X_dev,words_ids[0], words_ids[1])\n","        else:\n","            dv_positive = 0\n","            dv_negative = 0\n","            \n","        if cv != 0:\n","            cv_positive = int(cv * positive_length/(positive_length + negative_length))\n","            cv_negative = cv - cv_positive\n","            cv_data_targets = np.concatenate((positive_data_targets[dv_positive:dv_positive + cv_positive,:], negative_data_targets[dv_negative:dv_negative + cv_negative,:]))\n","            cv_data_targets = cv_data_targets[np.random.permutation(cv), :]\n","            self.cv_targets = cv_data_targets[:,1].astype(float)\n","            X_cross = self.__tokenize__(cv_data_targets[:,0])\n","            self.X_cv_lengths = np.array(list(map(len, X_cross)))\n","            if words_ids == None:\n","                self.cv_data = X_cross\n","            else:\n","                self.cv_data = self.__ids_and_pad__(X_cross,words_ids[0], words_ids[1])   \n","        else:\n","            cv_positive = 0\n","            cv_negative = 0\n","            \n","        train_data_targets = np.concatenate((positive_data_targets[dv_positive + cv_positive:,:], negative_data_targets[dv_negative + cv_negative:,:]))\n","        train_data_targets = train_data_targets[np.random.permutation(len(data_targets)-dv-cv), :]\n","        self.train_targets = train_data_targets[:,1].astype(float)\n","        X_train = self.__tokenize__(train_data_targets[:,0])\n","        self.X_train_lengths = np.array(list(map(len, X_train)))\n","        if words_ids == None:\n","            self.train_data = X_train\n","        else:\n","            self.train_data = self.__ids_and_pad__(X_train ,words_ids[0], words_ids[1])\n","        self.num_train_examples = len(self.train_targets)\n","        self.nr_batches = self.num_train_examples//self.batch_length\n","    \n","    def __tokenize__(self, X):\n","        return [re.findall(r\"[\\w]+|[']|[.,!?;]\", str(x)) for x in X]\n","    \n","    def __ids_and_pad__(self, X, word_ids, width):\n","        padded_X = np.zeros((len(X),width))\n","        i = 0\n","        for sentence in X:\n","            j = 0\n","            for word in sentence:\n","                padded_X[i,j] = word_ids[word]\n","                j += 1\n","            i +=1\n","        return padded_X\n","    \n","    def cross_val_set(self):\n","        return self.X_cv_lengths, self.cv_data, self.cv_targets \n","    \n","    def dev_set(self):\n","        return self.X_dv_lengths, self.dv_data, self.dv_targets\n","    \n","    def next_batch(self):\n","        self.pointer += 1\n","        X_batch = self.train_data[(self.pointer - 1)*self.batch_length:self.pointer*self.batch_length]\n","        y_batch = self.train_targets[(self.pointer - 1)*self.batch_length:self.pointer*self.batch_length]\n","        X_batch_lengths = self.X_train_lengths[(self.pointer - 1)*self.batch_length:self.pointer*self.batch_length]\n","        \n","        if self.pointer == self.nr_batches:\n","            self.pointer = 0\n","            self.reshuffle_seed += 1\n","            np.random.seed(self.seed + self.reshuffle_seed)\n","            permutations = np.random.permutation(self.num_train_examples)\n","            self.train_data = self.train_data[permutations]\n","            self.train_targets = self.train_targets[permutations]\n","            self.X_train_lengths = self.X_train_lengths[permutations]\n","            \n","        return X_batch_lengths, X_batch, y_batch\n","    \n","    def reset(self):\n","        self.pointer = 0        "],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"8OJMLwdPV757"},"cell_type":"markdown","source":["# Load and prepare data"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1544112867537,"user_tz":-120,"elapsed":47104,"user":{"displayName":"Quentin Legrand","photoUrl":"https://lh6.googleusercontent.com/-IXHiOGs04sE/AAAAAAAAAAI/AAAAAAAAAFk/ppsEvqzCcGw/s64/photo.jpg","userId":"00421493000358847389"}},"id":"06xzg79TV75-","outputId":"a948fe21-6e28-4285-c0b1-c96b73f57beb","colab":{"base_uri":"https://localhost:8080/","height":206}},"cell_type":"code","source":["train_data = load_data()\n","train_data.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid</th>\n","      <th>target</th>\n","      <th>corrected_question_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00002165364db923c7e6</td>\n","      <td>0</td>\n","      <td>How did Quebec nationalists see their province...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000032939017120e6e44</td>\n","      <td>0</td>\n","      <td>Do you have an adopted dog , how would you enc...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0000412ca6e4628ce2cf</td>\n","      <td>0</td>\n","      <td>Why does velocity affect time ? Does velocity ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000042bf85aa498cd78e</td>\n","      <td>0</td>\n","      <td>How did Otto von Guericke used the Magdeburg h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0000455dfa3e01eae3af</td>\n","      <td>0</td>\n","      <td>Can I convert montra helicon D to a mountain b...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    qid  target  \\\n","0  00002165364db923c7e6       0   \n","1  000032939017120e6e44       0   \n","2  0000412ca6e4628ce2cf       0   \n","3  000042bf85aa498cd78e       0   \n","4  0000455dfa3e01eae3af       0   \n","\n","                             corrected_question_text  \n","0  How did Quebec nationalists see their province...  \n","1  Do you have an adopted dog , how would you enc...  \n","2  Why does velocity affect time ? Does velocity ...  \n","3  How did Otto von Guericke used the Magdeburg h...  \n","4  Can I convert montra helicon D to a mountain b...  "]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"colab_type":"code","id":"TFTmNHrfV76L","colab":{}},"cell_type":"code","source":["data_targets = df_to_data_target(train_data)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"s8-E1GHuV76V","colab":{}},"cell_type":"code","source":["tokenized_questions = tokenize(train_data[\"corrected_question_text\"].values)\n","vocabulary_in_set = get_vocab(tokenized_questions)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"31VolUA5V76l","colab":{}},"cell_type":"code","source":["embeddings, words_ids = glove_embeddings(vocabulary_in_set=vocabulary_in_set)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"pOVK2aYgV77U"},"cell_type":"markdown","source":["# Construction phase"]},{"metadata":{"colab_type":"code","id":"er4v1HWSV77a","colab":{}},"cell_type":"code","source":["reset_graph()\n","\n","#n_inputs = 300\n","n_neurons = [500, 500, 500]\n","n_fc1 = 500\n","n_fc2 = 500\n","n_fc3 = 500\n","n_fc4 = 100\n","n_output = 1\n","learning_rate = 0.01\n","activation_fn = tf.nn.elu\n","\n","n_steps = 250\n","seq_len = tf.placeholder(tf.int32, [None], name=\"seq_len\")\n","\n","X = tf.placeholder(tf.int32, [None, n_steps], name=\"X\")\n","y = tf.placeholder(tf.float32, [None], name=\"y\")\n","\n","with tf.name_scope(\"embedding_layer\"):\n","    word_embeddings = tf.Variable(initial_value=embeddings, trainable=False)\n","    embedded_sentences = tf.nn.embedding_lookup(word_embeddings, X)\n","\n","with tf.name_scope(\"shallow_LSTM_layer\"):\n","    lstm_cell = [tf.contrib.rnn.LSTMCell(num_units=n, name=\"LSTM\") for n in n_neurons]\n","    multi_lstm_cell = tf.contrib.rnn.MultiRNNCell(lstm_cell)\n","    h_states, states = tf.nn.dynamic_rnn(multi_lstm_cell, embedded_sentences, dtype = tf.float32, sequence_length=seq_len)\n","\n","with tf.name_scope(\"fully_connected_layers\"):\n","    fc1 = tf.contrib.layers.fully_connected(states[0][0], n_fc1, activation_fn=activation_fn)\n","    fc2 = tf.contrib.layers.fully_connected(fc1 + states[1][0], n_fc2, activation_fn=activation_fn)\n","    fc3 = tf.contrib.layers.fully_connected(fc2 + states[2][0], n_fc3, activation_fn=activation_fn)\n","    fc4 = tf.contrib.layers.fully_connected(fc3, n_fc4, activation_fn=activation_fn)\n","\n","with tf.name_scope(\"logits_and_outputs\"):\n","    logits = tf.reshape(tf.contrib.layers.fully_connected(fc4, n_output, activation_fn=None),shape=[-1])\n","    outputs = tf.sigmoid(logits)\n","    predictions = tf.round(outputs)\n","\n","with tf.name_scope(\"loss\"):\n","    xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n","    loss = tf.reduce_mean(xentropy)\n","\n","with tf.name_scope(\"evaluation\"):\n","    TP = tf.count_nonzero(predictions * y)\n","    TN = tf.count_nonzero((predictions - 1) * (y - 1))\n","    FP = tf.count_nonzero(predictions * (y - 1))\n","    FN = tf.count_nonzero((predictions - 1) * y)\n","    precision = TP / (TP + FP)\n","    recall = TP / (TP + FN)\n","    accuracy = (TP + TN)/(TP + FP + TN + FN)\n","    f1 = 2 * precision * recall / (precision + recall)\n","\n","with tf.name_scope(\"training_op\"):\n","    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","    training_op = optimizer.minimize(loss)\n","\n","init = tf.global_variables_initializer()\n","saver = tf.train.Saver()\n","\n","f1_train_summary = tf.summary.scalar('Train_F1_score', f1)\n","f1_dev_summary = tf.summary.scalar(\"Dev_F1_score\", f1)\n","loss_train_summary = tf.summary.scalar(\"Train_loss\", loss)\n","loss_dev_summary = tf.summary.scalar(\"Dev_loss\", loss)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"-66y9w6WV77g"},"cell_type":"markdown","source":["# Training phase"]},{"metadata":{"colab_type":"code","id":"MayLFImnV77p","colab":{}},"cell_type":"code","source":["batch_size = 500\n","\n","QIQC = data_split_and_batch(data_targets, cv=1000, dv=1000, batch_size=batch_size, words_ids=(words_ids,n_steps))\n","X_dev_lengths, X_dev_set, y_dev_set = QIQC.dev_set()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1544127394728,"user_tz":-120,"elapsed":10591161,"user":{"displayName":"Quentin Legrand","photoUrl":"https://lh6.googleusercontent.com/-IXHiOGs04sE/AAAAAAAAAAI/AAAAAAAAAFk/ppsEvqzCcGw/s64/photo.jpg","userId":"00421493000358847389"}},"id":"U6YJBLgtV775","outputId":"d3193cda-f95c-4aca-b8c9-be3551e77145","colab":{"base_uri":"https://localhost:8080/","height":2515}},"cell_type":"code","source":["QIQC.reset()\n","n_epoch = 5\n","\n","now = dt.utcnow().strftime(\"%Y%m%d%H%M%S\")\n","LOGS_FOLDER = \"logs/run-{}/\".format(now)\n","MODELS_FILE = \"models/model2/QIQC_model2.ckpt\"\n","MODELS_INDEX = \"models/model2/QIQC_model2.ckpt.index\"\n","logdir = os.path.join(DRIVE_PATH,LOGS_FOLDER)\n","modfil = os.path.join(DRIVE_PATH,MODELS_FILE)\n","modind = os.path.join(DRIVE_PATH,MODELS_INDEX)\n","file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n","total_deltas = 0\n","t_init = time.time()\n","with tf.Session() as sess:\n","    init.run()\n","    t_0 = time.time()\n","    for epoch in range(n_epoch):\n","        for iteration in range(QIQC.nr_batches):\n","            X_lengths, X_batch, y_batch = QIQC.next_batch()\n","            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, seq_len: X_lengths})\n","\n","            if iteration % 30 == 0 :\n","                f1_train_str, loss_train_str = sess.run([f1_train_summary, loss_train_summary],feed_dict = {X : X_batch, y : y_batch, seq_len: X_lengths})\n","                f1_dev_str, loss_dev_str = sess.run([f1_dev_summary, loss_dev_summary], feed_dict = {X : X_dev_set, y : y_dev_set, seq_len: X_dev_lengths})\n","                step = epoch * QIQC.nr_batches + iteration\n","                file_writer.add_summary(f1_train_str, step)\n","                file_writer.add_summary(f1_dev_str, step)\n","                file_writer.add_summary(loss_train_str, step)\n","                file_writer.add_summary(loss_dev_str, step)\n","\n","            if iteration % 1000 == 0:\n","                save_path = saver.save(sess,modfil)\n","            if iteration % 100 == 0:\n","                f1_train, loss_train = sess.run([f1, loss],feed_dict = {X : X_batch, y : y_batch, seq_len: X_lengths})\n","                f1_dev, loss_dev = sess.run([f1, loss], feed_dict = {X : X_dev_set, y : y_dev_set, seq_len: X_dev_lengths})\n","                t_1 = time.time()\n","                t_delta = t_1 - t_0\n","                total_deltas += t_delta\n","                expected_runtime = t_delta * ((n_epoch - epoch - 1) * QIQC.nr_batches + (QIQC.nr_batches - iteration))/100\n","                expected_runtime_h = int(expected_runtime//3600)\n","                expected_runtime_min = int((expected_runtime - 3600 * expected_runtime_h)//60)\n","                expected_runtime_sec = int((expected_runtime - 3600 * expected_runtime_h - 60 * expected_runtime_min))\n","                t_0 = t_1\n","                print(\"Ep. {}/{}; It. {}/{}; Runtime {:.2f} s; Remaining runtime {}h{}min{}s; f1_train {:.4f}; f1_dev {:.4f}; loss_train {:.4f}; loss_dev {:.4f}\".format(epoch + 1, n_epoch, iteration, QIQC.nr_batches, t_delta, expected_runtime_h,expected_runtime_min,expected_runtime_sec,f1_train,f1_dev,loss_train,loss_dev))\n","\n","t_final = time.time()\n","actual_runtime_h = int((t_final - t_init)//3600)\n","actual_runtime_min = int((t_final - t_init - 3600 * actual_runtime_h)//60)\n","actual_runtime_sec = int((t_final - t_init - 3600 * actual_runtime_h - 60 * actual_runtime_min))\n","\n","print(\"Total actual runtime: {} hours {} min {} sec\".format(actual_runtime_h, actual_runtime_min, actual_runtime_sec))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Ep. 1/5; It. 0/2608; Runtime 7.56 s; Remaining runtime 0h16min25s; f1_train nan; f1_dev nan; loss_train 13.7627; loss_dev 13.4973\n","Ep. 1/5; It. 100/2608; Runtime 81.94 s; Remaining runtime 2h56min42s; f1_train nan; f1_dev nan; loss_train 0.1617; loss_dev 0.1874\n","Ep. 1/5; It. 200/2608; Runtime 80.48 s; Remaining runtime 2h52min13s; f1_train nan; f1_dev nan; loss_train 0.1609; loss_dev 0.1837\n","Ep. 1/5; It. 300/2608; Runtime 81.07 s; Remaining runtime 2h52min8s; f1_train nan; f1_dev nan; loss_train 0.1249; loss_dev 0.1447\n","Ep. 1/5; It. 400/2608; Runtime 81.12 s; Remaining runtime 2h50min54s; f1_train 0.5588; f1_dev 0.5185; loss_train 0.1494; loss_dev 0.1398\n","Ep. 1/5; It. 500/2608; Runtime 80.50 s; Remaining runtime 2h48min14s; f1_train 0.4103; f1_dev 0.4301; loss_train 0.1236; loss_dev 0.1300\n","Ep. 1/5; It. 600/2608; Runtime 80.02 s; Remaining runtime 2h45min54s; f1_train 0.6392; f1_dev 0.5487; loss_train 0.1626; loss_dev 0.1334\n","Ep. 1/5; It. 700/2608; Runtime 83.98 s; Remaining runtime 2h52min42s; f1_train 0.5714; f1_dev 0.5289; loss_train 0.1511; loss_dev 0.1316\n","Ep. 1/5; It. 800/2608; Runtime 80.70 s; Remaining runtime 2h44min37s; f1_train 0.7111; f1_dev 0.5600; loss_train 0.0821; loss_dev 0.1183\n","Ep. 1/5; It. 900/2608; Runtime 82.57 s; Remaining runtime 2h47min3s; f1_train 0.5263; f1_dev 0.4889; loss_train 0.1061; loss_dev 0.1221\n","Ep. 1/5; It. 1000/2608; Runtime 85.26 s; Remaining runtime 2h51min5s; f1_train 0.6415; f1_dev 0.5510; loss_train 0.1074; loss_dev 0.1161\n","Ep. 1/5; It. 1100/2608; Runtime 81.19 s; Remaining runtime 2h41min33s; f1_train 0.4737; f1_dev 0.5106; loss_train 0.1071; loss_dev 0.1273\n","Ep. 1/5; It. 1200/2608; Runtime 82.16 s; Remaining runtime 2h42min7s; f1_train 0.6222; f1_dev 0.5400; loss_train 0.1012; loss_dev 0.1151\n","Ep. 1/5; It. 1300/2608; Runtime 81.04 s; Remaining runtime 2h38min34s; f1_train 0.6176; f1_dev 0.5691; loss_train 0.1313; loss_dev 0.1268\n","Ep. 1/5; It. 1400/2608; Runtime 80.18 s; Remaining runtime 2h35min32s; f1_train 0.5417; f1_dev 0.5490; loss_train 0.1059; loss_dev 0.1199\n","Ep. 1/5; It. 1500/2608; Runtime 81.57 s; Remaining runtime 2h36min52s; f1_train 0.4348; f1_dev 0.5545; loss_train 0.1079; loss_dev 0.1142\n","Ep. 1/5; It. 1600/2608; Runtime 81.27 s; Remaining runtime 2h34min57s; f1_train 0.6562; f1_dev 0.5800; loss_train 0.0987; loss_dev 0.1127\n","Ep. 1/5; It. 1700/2608; Runtime 80.62 s; Remaining runtime 2h32min22s; f1_train 0.4815; f1_dev 0.5000; loss_train 0.1201; loss_dev 0.1136\n","Ep. 1/5; It. 1800/2608; Runtime 81.43 s; Remaining runtime 2h32min32s; f1_train 0.7059; f1_dev 0.5161; loss_train 0.1162; loss_dev 0.1119\n","Ep. 1/5; It. 1900/2608; Runtime 80.32 s; Remaining runtime 2h29min7s; f1_train 0.6182; f1_dev 0.5361; loss_train 0.1159; loss_dev 0.1112\n","Ep. 1/5; It. 2000/2608; Runtime 83.13 s; Remaining runtime 2h32min57s; f1_train 0.5200; f1_dev 0.6261; loss_train 0.1203; loss_dev 0.1160\n","Ep. 1/5; It. 2100/2608; Runtime 82.33 s; Remaining runtime 2h30min6s; f1_train 0.6027; f1_dev 0.6080; loss_train 0.1447; loss_dev 0.1268\n","Ep. 1/5; It. 2200/2608; Runtime 83.40 s; Remaining runtime 2h30min40s; f1_train 0.4242; f1_dev 0.4884; loss_train 0.0848; loss_dev 0.1133\n","Ep. 1/5; It. 2300/2608; Runtime 80.18 s; Remaining runtime 2h23min31s; f1_train 0.7077; f1_dev 0.5983; loss_train 0.1030; loss_dev 0.1113\n","Ep. 1/5; It. 2400/2608; Runtime 81.57 s; Remaining runtime 2h24min38s; f1_train 0.6000; f1_dev 0.5849; loss_train 0.1011; loss_dev 0.1114\n","Ep. 1/5; It. 2500/2608; Runtime 80.68 s; Remaining runtime 2h21min43s; f1_train 0.6522; f1_dev 0.5660; loss_train 0.1063; loss_dev 0.1102\n","Ep. 1/5; It. 2600/2608; Runtime 80.43 s; Remaining runtime 2h19min56s; f1_train 0.5556; f1_dev 0.4944; loss_train 0.1225; loss_dev 0.1129\n","Ep. 2/5; It. 0/2608; Runtime 14.95 s; Remaining runtime 0h25min59s; f1_train 0.7586; f1_dev 0.5714; loss_train 0.0801; loss_dev 0.1094\n","Ep. 2/5; It. 100/2608; Runtime 81.02 s; Remaining runtime 2h19min31s; f1_train 0.6341; f1_dev 0.5361; loss_train 0.0855; loss_dev 0.1120\n","Ep. 2/5; It. 200/2608; Runtime 81.22 s; Remaining runtime 2h18min30s; f1_train 0.6984; f1_dev 0.5474; loss_train 0.1051; loss_dev 0.1113\n","Ep. 2/5; It. 300/2608; Runtime 82.06 s; Remaining runtime 2h18min34s; f1_train 0.3448; f1_dev 0.4000; loss_train 0.1042; loss_dev 0.1326\n","Ep. 2/5; It. 400/2608; Runtime 81.22 s; Remaining runtime 2h15min48s; f1_train 0.6552; f1_dev 0.6102; loss_train 0.1087; loss_dev 0.1122\n","Ep. 2/5; It. 500/2608; Runtime 80.65 s; Remaining runtime 2h13min30s; f1_train 0.7000; f1_dev 0.5686; loss_train 0.1102; loss_dev 0.1084\n","Ep. 2/5; It. 600/2608; Runtime 81.61 s; Remaining runtime 2h13min44s; f1_train 0.6667; f1_dev 0.5714; loss_train 0.1000; loss_dev 0.1103\n","Ep. 2/5; It. 700/2608; Runtime 80.48 s; Remaining runtime 2h10min31s; f1_train 0.6667; f1_dev 0.5600; loss_train 0.0899; loss_dev 0.1097\n","Ep. 2/5; It. 800/2608; Runtime 81.20 s; Remaining runtime 2h10min21s; f1_train 0.5385; f1_dev 0.6168; loss_train 0.1412; loss_dev 0.1053\n","Ep. 2/5; It. 900/2608; Runtime 83.22 s; Remaining runtime 2h12min12s; f1_train 0.7027; f1_dev 0.6316; loss_train 0.1146; loss_dev 0.1070\n","Ep. 2/5; It. 1000/2608; Runtime 84.67 s; Remaining runtime 2h13min6s; f1_train 0.5926; f1_dev 0.6667; loss_train 0.1291; loss_dev 0.1044\n","Ep. 2/5; It. 1100/2608; Runtime 79.65 s; Remaining runtime 2h3min52s; f1_train 0.8060; f1_dev 0.6667; loss_train 0.0789; loss_dev 0.1047\n","Ep. 2/5; It. 1200/2608; Runtime 80.79 s; Remaining runtime 2h4min18s; f1_train 0.6038; f1_dev 0.5474; loss_train 0.1098; loss_dev 0.1121\n","Ep. 2/5; It. 1300/2608; Runtime 80.65 s; Remaining runtime 2h2min45s; f1_train 0.7200; f1_dev 0.5895; loss_train 0.0880; loss_dev 0.1094\n","Ep. 2/5; It. 1400/2608; Runtime 80.53 s; Remaining runtime 2h1min13s; f1_train 0.7200; f1_dev 0.6333; loss_train 0.1127; loss_dev 0.1114\n","Ep. 2/5; It. 1500/2608; Runtime 80.31 s; Remaining runtime 1h59min33s; f1_train 0.4928; f1_dev 0.6364; loss_train 0.1525; loss_dev 0.1067\n","Ep. 2/5; It. 1600/2608; Runtime 82.22 s; Remaining runtime 2h1min1s; f1_train 0.6753; f1_dev 0.6429; loss_train 0.1114; loss_dev 0.1060\n","Ep. 2/5; It. 1700/2608; Runtime 82.08 s; Remaining runtime 1h59min27s; f1_train 0.7308; f1_dev 0.5905; loss_train 0.0864; loss_dev 0.1118\n","Ep. 2/5; It. 1800/2608; Runtime 81.07 s; Remaining runtime 1h56min37s; f1_train 0.6667; f1_dev 0.5862; loss_train 0.1305; loss_dev 0.1175\n","Ep. 2/5; It. 1900/2608; Runtime 82.67 s; Remaining runtime 1h57min33s; f1_train 0.6316; f1_dev 0.5376; loss_train 0.1000; loss_dev 0.1151\n","Ep. 2/5; It. 2000/2608; Runtime 85.02 s; Remaining runtime 1h59min28s; f1_train 0.6909; f1_dev 0.6019; loss_train 0.0900; loss_dev 0.1080\n","Ep. 2/5; It. 2100/2608; Runtime 80.63 s; Remaining runtime 1h51min57s; f1_train 0.4651; f1_dev 0.5227; loss_train 0.1249; loss_dev 0.1271\n","Ep. 2/5; It. 2200/2608; Runtime 81.92 s; Remaining runtime 1h52min23s; f1_train 0.5455; f1_dev 0.6481; loss_train 0.1248; loss_dev 0.1027\n","Ep. 2/5; It. 2300/2608; Runtime 80.06 s; Remaining runtime 1h48min30s; f1_train 0.5333; f1_dev 0.6154; loss_train 0.1465; loss_dev 0.0999\n","Ep. 2/5; It. 2400/2608; Runtime 82.39 s; Remaining runtime 1h50min17s; f1_train 0.5532; f1_dev 0.5872; loss_train 0.1075; loss_dev 0.1054\n","Ep. 2/5; It. 2500/2608; Runtime 81.08 s; Remaining runtime 1h47min11s; f1_train 0.7170; f1_dev 0.6261; loss_train 0.0877; loss_dev 0.1010\n","Ep. 2/5; It. 2600/2608; Runtime 80.01 s; Remaining runtime 1h44min26s; f1_train 0.6154; f1_dev 0.6154; loss_train 0.1282; loss_dev 0.0973\n","Ep. 3/5; It. 0/2608; Runtime 15.17 s; Remaining runtime 0h19min46s; f1_train 0.6102; f1_dev 0.6111; loss_train 0.0995; loss_dev 0.0963\n","Ep. 3/5; It. 100/2608; Runtime 81.42 s; Remaining runtime 1h44min48s; f1_train 0.6207; f1_dev 0.5833; loss_train 0.0965; loss_dev 0.0960\n","Ep. 3/5; It. 200/2608; Runtime 80.19 s; Remaining runtime 1h41min53s; f1_train 0.5625; f1_dev 0.6446; loss_train 0.1556; loss_dev 0.1187\n","Ep. 3/5; It. 300/2608; Runtime 83.23 s; Remaining runtime 1h44min22s; f1_train 0.6471; f1_dev 0.6214; loss_train 0.0701; loss_dev 0.0981\n","Ep. 3/5; It. 400/2608; Runtime 81.32 s; Remaining runtime 1h40min37s; f1_train 0.7059; f1_dev 0.5773; loss_train 0.0756; loss_dev 0.1124\n","Ep. 3/5; It. 500/2608; Runtime 79.85 s; Remaining runtime 1h37min28s; f1_train 0.6857; f1_dev 0.6333; loss_train 0.1064; loss_dev 0.1047\n","Ep. 3/5; It. 600/2608; Runtime 81.71 s; Remaining runtime 1h38min22s; f1_train 0.5581; f1_dev 0.5474; loss_train 0.0984; loss_dev 0.1156\n","Ep. 3/5; It. 700/2608; Runtime 81.09 s; Remaining runtime 1h36min16s; f1_train 0.4615; f1_dev 0.5306; loss_train 0.1176; loss_dev 0.1261\n","Ep. 3/5; It. 800/2608; Runtime 79.32 s; Remaining runtime 1h32min51s; f1_train nan; f1_dev nan; loss_train 0.2324; loss_dev 0.2297\n","Ep. 3/5; It. 900/2608; Runtime 79.74 s; Remaining runtime 1h32min0s; f1_train nan; f1_dev nan; loss_train 0.1874; loss_dev 0.2300\n","Ep. 3/5; It. 1000/2608; Runtime 84.72 s; Remaining runtime 1h36min21s; f1_train nan; f1_dev nan; loss_train 0.2053; loss_dev 0.2297\n","Ep. 3/5; It. 1100/2608; Runtime 79.94 s; Remaining runtime 1h29min35s; f1_train nan; f1_dev nan; loss_train 0.2641; loss_dev 0.2301\n","Ep. 3/5; It. 1200/2608; Runtime 80.84 s; Remaining runtime 1h29min14s; f1_train nan; f1_dev nan; loss_train 0.1844; loss_dev 0.2298\n","Ep. 3/5; It. 1300/2608; Runtime 79.11 s; Remaining runtime 1h26min1s; f1_train nan; f1_dev nan; loss_train 0.2101; loss_dev 0.2301\n","Ep. 3/5; It. 1400/2608; Runtime 79.93 s; Remaining runtime 1h25min34s; f1_train nan; f1_dev nan; loss_train 0.2110; loss_dev 0.2298\n","Ep. 3/5; It. 1500/2608; Runtime 79.55 s; Remaining runtime 1h23min50s; f1_train nan; f1_dev nan; loss_train 0.2433; loss_dev 0.2297\n","Ep. 3/5; It. 1600/2608; Runtime 79.63 s; Remaining runtime 1h22min36s; f1_train nan; f1_dev nan; loss_train 0.2271; loss_dev 0.2298\n","Ep. 3/5; It. 1700/2608; Runtime 80.92 s; Remaining runtime 1h22min35s; f1_train nan; f1_dev nan; loss_train 0.2221; loss_dev 0.2309\n","Ep. 3/5; It. 1800/2608; Runtime 79.76 s; Remaining runtime 1h20min4s; f1_train nan; f1_dev nan; loss_train 0.1990; loss_dev 0.2298\n","Ep. 3/5; It. 1900/2608; Runtime 78.40 s; Remaining runtime 1h17min24s; f1_train nan; f1_dev nan; loss_train 0.2045; loss_dev 0.2300\n","Ep. 3/5; It. 2000/2608; Runtime 84.42 s; Remaining runtime 1h21min56s; f1_train nan; f1_dev nan; loss_train 0.2045; loss_dev 0.2313\n","Ep. 3/5; It. 2100/2608; Runtime 80.47 s; Remaining runtime 1h16min46s; f1_train nan; f1_dev nan; loss_train 0.2537; loss_dev 0.2302\n","Ep. 3/5; It. 2200/2608; Runtime 80.30 s; Remaining runtime 1h15min16s; f1_train nan; f1_dev nan; loss_train 0.2433; loss_dev 0.2297\n","Ep. 3/5; It. 2300/2608; Runtime 79.91 s; Remaining runtime 1h13min34s; f1_train nan; f1_dev nan; loss_train 0.2836; loss_dev 0.2329\n","Ep. 3/5; It. 2400/2608; Runtime 81.03 s; Remaining runtime 1h13min15s; f1_train nan; f1_dev nan; loss_train 0.2440; loss_dev 0.2299\n","Ep. 3/5; It. 2500/2608; Runtime 79.80 s; Remaining runtime 1h10min48s; f1_train nan; f1_dev nan; loss_train 0.1961; loss_dev 0.2301\n","Ep. 3/5; It. 2600/2608; Runtime 79.36 s; Remaining runtime 1h9min5s; f1_train nan; f1_dev nan; loss_train 0.1876; loss_dev 0.2299\n","Ep. 4/5; It. 0/2608; Runtime 14.95 s; Remaining runtime 0h12min59s; f1_train nan; f1_dev nan; loss_train 0.2216; loss_dev 0.2297\n","Ep. 4/5; It. 100/2608; Runtime 78.83 s; Remaining runtime 1h7min13s; f1_train nan; f1_dev nan; loss_train 0.2826; loss_dev 0.2298\n","Ep. 4/5; It. 200/2608; Runtime 80.29 s; Remaining runtime 1h7min7s; f1_train nan; f1_dev nan; loss_train 0.2569; loss_dev 0.2306\n","Ep. 4/5; It. 300/2608; Runtime 81.66 s; Remaining runtime 1h6min54s; f1_train nan; f1_dev nan; loss_train 0.2044; loss_dev 0.2304\n","Ep. 4/5; It. 400/2608; Runtime 79.24 s; Remaining runtime 1h3min36s; f1_train nan; f1_dev nan; loss_train 0.2217; loss_dev 0.2303\n","Ep. 4/5; It. 500/2608; Runtime 79.66 s; Remaining runtime 1h2min36s; f1_train nan; f1_dev nan; loss_train 0.2485; loss_dev 0.2306\n","Ep. 4/5; It. 600/2608; Runtime 80.49 s; Remaining runtime 1h1min55s; f1_train nan; f1_dev nan; loss_train 0.2690; loss_dev 0.2307\n","Ep. 4/5; It. 700/2608; Runtime 77.87 s; Remaining runtime 0h58min36s; f1_train nan; f1_dev nan; loss_train 0.1840; loss_dev 0.2298\n","Ep. 4/5; It. 800/2608; Runtime 79.42 s; Remaining runtime 0h58min26s; f1_train nan; f1_dev nan; loss_train 0.2218; loss_dev 0.2298\n","Ep. 4/5; It. 900/2608; Runtime 80.43 s; Remaining runtime 0h57min51s; f1_train nan; f1_dev nan; loss_train 0.2227; loss_dev 0.2318\n","Ep. 4/5; It. 1000/2608; Runtime 82.49 s; Remaining runtime 0h57min57s; f1_train nan; f1_dev nan; loss_train 0.2442; loss_dev 0.2319\n","Ep. 4/5; It. 1100/2608; Runtime 80.25 s; Remaining runtime 0h55min3s; f1_train nan; f1_dev nan; loss_train 0.1960; loss_dev 0.2301\n","Ep. 4/5; It. 1200/2608; Runtime 81.95 s; Remaining runtime 0h54min51s; f1_train nan; f1_dev nan; loss_train 0.2380; loss_dev 0.2301\n","Ep. 4/5; It. 1300/2608; Runtime 80.32 s; Remaining runtime 0h52min25s; f1_train nan; f1_dev nan; loss_train 0.2491; loss_dev 0.2297\n","Ep. 4/5; It. 1400/2608; Runtime 79.75 s; Remaining runtime 0h50min43s; f1_train nan; f1_dev nan; loss_train 0.2188; loss_dev 0.2313\n","Ep. 4/5; It. 1500/2608; Runtime 80.24 s; Remaining runtime 0h49min41s; f1_train nan; f1_dev nan; loss_train 0.2270; loss_dev 0.2297\n","Ep. 4/5; It. 1600/2608; Runtime 78.81 s; Remaining runtime 0h47min29s; f1_train nan; f1_dev nan; loss_train 0.1557; loss_dev 0.2331\n","Ep. 4/5; It. 1700/2608; Runtime 79.77 s; Remaining runtime 0h46min44s; f1_train nan; f1_dev nan; loss_train 0.2174; loss_dev 0.2328\n","Ep. 4/5; It. 1800/2608; Runtime 81.47 s; Remaining runtime 0h46min23s; f1_train nan; f1_dev nan; loss_train 0.2214; loss_dev 0.2298\n","Ep. 4/5; It. 1900/2608; Runtime 79.99 s; Remaining runtime 0h44min12s; f1_train nan; f1_dev nan; loss_train 0.2087; loss_dev 0.2312\n","Ep. 4/5; It. 2000/2608; Runtime 83.83 s; Remaining runtime 0h44min55s; f1_train nan; f1_dev nan; loss_train 0.2115; loss_dev 0.2300\n","Ep. 4/5; It. 2100/2608; Runtime 82.19 s; Remaining runtime 0h42min40s; f1_train nan; f1_dev nan; loss_train 0.2380; loss_dev 0.2301\n","Ep. 4/5; It. 2200/2608; Runtime 78.92 s; Remaining runtime 0h39min40s; f1_train nan; f1_dev nan; loss_train 0.2508; loss_dev 0.2305\n","Ep. 4/5; It. 2300/2608; Runtime 79.28 s; Remaining runtime 0h38min31s; f1_train nan; f1_dev nan; loss_train 0.2441; loss_dev 0.2316\n","Ep. 4/5; It. 2400/2608; Runtime 79.86 s; Remaining runtime 0h37min28s; f1_train nan; f1_dev nan; loss_train 0.2810; loss_dev 0.2297\n","Ep. 4/5; It. 2500/2608; Runtime 80.77 s; Remaining runtime 0h36min33s; f1_train nan; f1_dev nan; loss_train 0.2215; loss_dev 0.2297\n","Ep. 4/5; It. 2600/2608; Runtime 79.42 s; Remaining runtime 0h34min37s; f1_train nan; f1_dev nan; loss_train 0.2289; loss_dev 0.2314\n","Ep. 5/5; It. 0/2608; Runtime 15.88 s; Remaining runtime 0h6min54s; f1_train nan; f1_dev nan; loss_train 0.2540; loss_dev 0.2298\n","Ep. 5/5; It. 100/2608; Runtime 79.28 s; Remaining runtime 0h33min8s; f1_train nan; f1_dev nan; loss_train 0.2225; loss_dev 0.2315\n","Ep. 5/5; It. 200/2608; Runtime 80.00 s; Remaining runtime 0h32min6s; f1_train nan; f1_dev nan; loss_train 0.1986; loss_dev 0.2319\n","Ep. 5/5; It. 300/2608; Runtime 80.17 s; Remaining runtime 0h30min50s; f1_train nan; f1_dev nan; loss_train 0.2158; loss_dev 0.2300\n","Ep. 5/5; It. 400/2608; Runtime 80.72 s; Remaining runtime 0h29min42s; f1_train nan; f1_dev nan; loss_train 0.2447; loss_dev 0.2303\n","Ep. 5/5; It. 500/2608; Runtime 79.52 s; Remaining runtime 0h27min56s; f1_train nan; f1_dev nan; loss_train 0.2913; loss_dev 0.2298\n","Ep. 5/5; It. 600/2608; Runtime 81.12 s; Remaining runtime 0h27min8s; f1_train nan; f1_dev nan; loss_train 0.2489; loss_dev 0.2297\n","Ep. 5/5; It. 700/2608; Runtime 79.69 s; Remaining runtime 0h25min20s; f1_train nan; f1_dev nan; loss_train 0.2044; loss_dev 0.2306\n","Ep. 5/5; It. 800/2608; Runtime 79.58 s; Remaining runtime 0h23min58s; f1_train nan; f1_dev nan; loss_train 0.2333; loss_dev 0.2307\n","Ep. 5/5; It. 900/2608; Runtime 78.89 s; Remaining runtime 0h22min27s; f1_train nan; f1_dev nan; loss_train 0.2546; loss_dev 0.2328\n","Ep. 5/5; It. 1000/2608; Runtime 84.57 s; Remaining runtime 0h22min39s; f1_train nan; f1_dev nan; loss_train 0.2287; loss_dev 0.2312\n","Ep. 5/5; It. 1100/2608; Runtime 80.19 s; Remaining runtime 0h20min9s; f1_train nan; f1_dev nan; loss_train 0.2159; loss_dev 0.2303\n","Ep. 5/5; It. 1200/2608; Runtime 80.12 s; Remaining runtime 0h18min48s; f1_train nan; f1_dev nan; loss_train 0.2162; loss_dev 0.2297\n","Ep. 5/5; It. 1300/2608; Runtime 78.99 s; Remaining runtime 0h17min13s; f1_train nan; f1_dev nan; loss_train 0.2747; loss_dev 0.2300\n","Ep. 5/5; It. 1400/2608; Runtime 78.49 s; Remaining runtime 0h15min48s; f1_train nan; f1_dev nan; loss_train 0.2974; loss_dev 0.2297\n","Ep. 5/5; It. 1500/2608; Runtime 79.45 s; Remaining runtime 0h14min40s; f1_train nan; f1_dev nan; loss_train 0.2114; loss_dev 0.2299\n","Ep. 5/5; It. 1600/2608; Runtime 80.02 s; Remaining runtime 0h13min26s; f1_train nan; f1_dev nan; loss_train 0.2381; loss_dev 0.2303\n","Ep. 5/5; It. 1700/2608; Runtime 79.29 s; Remaining runtime 0h11min59s; f1_train nan; f1_dev nan; loss_train 0.2801; loss_dev 0.2300\n","Ep. 5/5; It. 1800/2608; Runtime 79.75 s; Remaining runtime 0h10min44s; f1_train nan; f1_dev nan; loss_train 0.2052; loss_dev 0.2297\n","Ep. 5/5; It. 1900/2608; Runtime 79.77 s; Remaining runtime 0h9min24s; f1_train nan; f1_dev nan; loss_train 0.2162; loss_dev 0.2297\n","Ep. 5/5; It. 2000/2608; Runtime 83.32 s; Remaining runtime 0h8min26s; f1_train nan; f1_dev nan; loss_train 0.2537; loss_dev 0.2301\n","Ep. 5/5; It. 2100/2608; Runtime 82.85 s; Remaining runtime 0h7min0s; f1_train nan; f1_dev nan; loss_train 0.2486; loss_dev 0.2308\n","Ep. 5/5; It. 2200/2608; Runtime 79.38 s; Remaining runtime 0h5min23s; f1_train nan; f1_dev nan; loss_train 0.2496; loss_dev 0.2299\n","Ep. 5/5; It. 2300/2608; Runtime 80.08 s; Remaining runtime 0h4min6s; f1_train nan; f1_dev nan; loss_train 0.2378; loss_dev 0.2298\n","Ep. 5/5; It. 2400/2608; Runtime 80.97 s; Remaining runtime 0h2min48s; f1_train nan; f1_dev nan; loss_train 0.2575; loss_dev 0.2309\n","Ep. 5/5; It. 2500/2608; Runtime 80.23 s; Remaining runtime 0h1min26s; f1_train nan; f1_dev nan; loss_train 0.2166; loss_dev 0.2316\n","Ep. 5/5; It. 2600/2608; Runtime 79.79 s; Remaining runtime 0h0min6s; f1_train nan; f1_dev nan; loss_train 0.2271; loss_dev 0.2298\n","Total actual runtime: 2 hours 56 min 26 sec\n"],"name":"stdout"}]}]}